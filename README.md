# Proyecto de AnÃ¡lisis de ArtÃ­culos CientÃ­ficos con Grobid ğŸ§ ğŸ“Š


[![Python](https://img.shields.io/badge/Python-3.8%2B-red)](https://www.python.org/)

[![Docker](https://img.shields.io/badge/Docker-Requiere-2496ED)](https://www.docker.com/)

[![Licencia](https://img.shields.io/badge/Licencia-Apache%202.0-green)](https://www.apache.org/licenses/LICENSE-2.0)

[![DOI](https://zenodo.org/badge/927880683.svg)](https://doi.org/10.5281/zenodo.14894307)

[![Automated Release Notes by MdÃ­az](https://img.shields.io/badge/%F0%9F%A4%96-release%20notes-00B2EE.svg)](https://github.com/Mdiaz-ai/iaCienciaAbierta/releases)

# Herramienta automatizada para extraer y visualizar datos de artÃ­culos acadÃ©micos en PDF. Genera:

- ğŸŒ¥ï¸ **Nubes de palabras** de resÃºmenes

- ğŸ“ˆ **GrÃ¡ficos de figuras** por artÃ­culo

- ğŸ”— **Listados de enlaces** externos



# ConfiguraciÃ³n del Entorno ğŸ

### OpciÃ³n 1: Con Conda (recomendado)


## Crear entorno
```bash
conda create -n cienciaabierta python=3.9
```

## Activar entorno
```bash
conda activate cienciaabierta
```

## Instalar dependencias
```bash
conda install -c conda-forge wordcloud matplotlib numpy pillow requests
```
### TambiÃ©n se como se menciona mÃ¡s abajo se puede hacer pip install -r requirements.txt

## Verificar instalaciÃ³n
```bash
conda list
```

### OpciÃ³n 2: Con venv (Python nativo)

## Crear entorno
```bash
python -m venv .venv
```

## Activar entorno (Linux/Mac)
```bash
source .venv/bin/activate
```

## Activar entorno (Windows)
```bash
.venv\Scripts\activate
```

## Instalar dependencias
```bash
pip install -r requirements.txt
```


# Requisitos Previos âš™ï¸
-**Docker** ([GuÃ­a de instalaciÃ³n](https://docs.docker.com/get-docker/))

- **Python 3.8+** y `pip`

- Memoria RAM recomendada: 4GB+ (para procesamiento simultÃ¡neo)



# InstalaciÃ³n ğŸ› ï¸

 ## Clonar el repositorio:
```bash
git clone https://github.com/Mdiaz-ai/iaCienciaAbierta.git iaCienciaAbierta
```

```bash
cd iaCienciaAbierta
```

## Instalar dependencias:
```bash
pip install -r requirements.txt
```

## Contenido de requirements.txt:

**wordcloud==1.8.2**

**matplotlib==3.7.1**

**numpy==1.24.3**

**pillow==8.3.2**

**requests==2.31.0**

**pytest**

**coverage**


# ConfiguraciÃ³n InicialğŸ³

Iniciar el servidor Grobid en Docker:
```bash
docker run -d --rm -p 8070:8070 --name grobid lfoppiano/grobid:0.7.2
```

Verificar que el servidor estÃ© activo:
```bash
curl http://localhost:8070/api/isalive  # Debe responder "true"
```

# Uso ğŸš€

Preparar archivos PDF:

Descomprimir la carpeta de pdfs.(En el caso de que se quieran aÃ±adir mÃ¡s o cambiar los documentos, simplemente, una vez descomprimida la carpeta, cambie el contenido y listo).

Procesar los documentos:
```bash
python procesar_pdfs.py    # Genera XML en la carpeta 'salida'
```
Generar resultados:

# Nubes de palabras (ventanas emergentes)
```bash
python generate_wordcloud.py
```
# GrÃ¡fico de figuras por artÃ­culo
```bash
python graficar.py
```
# Extraer enlaces a 'links.txt'
```bash
python links.py
```

Resultados Esperados ğŸ“‚
Carpeta/Archivo	DescripciÃ³n	Ejemplo
salida/*.xml	Metadatos estructurados en XML	procesado_articulo1.xml
WordCloud_*.png	Nubes de palabras interactivas	WordCloud
figure_chart.png	GrÃ¡fico de barras de figuras por artÃ­culo	Figuras
links.txt	Enlaces externos detectados	Enlaces

# Tests Unitarios ğŸ§ª

El proyecto incluye una suite completa de tests unitarios para verificar el correcto funcionamiento de cada componente sin necesidad de contar con archivos reales o una instalaciÃ³n de Grobid.

## Requisitos para Testing

Para ejecutar los tests, asegÃºrate de tener instaladas las dependencias adicionales:

```bash
pip install pytest coverage
```

O simplemente actualiza tu entorno usando el requirements.txt que ya incluye estas dependencias:

```bash
pip install -r requirements.txt
```

## EjecuciÃ³n de Tests

### Usando unittest (mÃ©todo estÃ¡ndar)

```bash
# Ejecutar todos los tests desde el directorio raÃ­z ia_def
python -m unittest discover -s tests

# Desde la carpeta principal del proyecto para ejecutar algÃºn test en concreto
python -m unittest discover -s tests -p "test_procesar_pdfs.py"
python -m unittest discover -s tests -p "test_links.py"
python -m unittest discover -s tests -p "test_graficar.py"
python -m unittest discover -s tests -p "test_wordcloud.py"
```

### Usando pytest (alternativa recomendada)

```bash
# Ejecutar todos los tests
pytest

# Ejecutar tests con informaciÃ³n detallada
pytest -v

# Ejecutar un archivo de tests especÃ­fico
pytest test_procesar_pdfs.py
```

### AnÃ¡lisis de Cobertura

Para evaluar quÃ© porcentaje del cÃ³digo estÃ¡ cubierto por los tests:

```bash
# Ejecutar tests con anÃ¡lisis de cobertura
coverage run -m pytest

# Ver informe de cobertura
coverage report

# Generar informe HTML detallado
coverage html
# El informe estarÃ¡ disponible en htmlcov/index.html
```

## Contenido de los Tests

- **test_procesar_pdfs.py**: Verifica el procesamiento de PDFs y la comunicaciÃ³n con Grobid
- **test_links.py**: Prueba la extracciÃ³n y filtrado de enlaces de los documentos XML
- **test_graficar.py**: Valida la generaciÃ³n de grÃ¡ficos sobre figuras encontradas
- **test_wordcloud.py**: Comprueba la extracciÃ³n de abstracts y generaciÃ³n de nubes de palabras

Los tests utilizan tÃ©cnicas de mock para simular interacciones con el sistema de archivos, APIs externas y bibliotecas grÃ¡ficas, permitiendo verificar la lÃ³gica del cÃ³digo sin dependencias externas.

## AÃ±adir Nuevos Tests

Si contribuyes al proyecto, asegÃºrate de aÃ±adir tests para las nuevas funcionalidades:

1. Crea un nuevo archivo `test_nombre_modulo.py`
2. Implementa clases de test heredando de `unittest.TestCase`
3. Usa mocks cuando sea necesario para aislar el cÃ³digo de dependencias externas
4. Verifica que los tests pasen antes de enviar un Pull Request




# SoluciÃ³n de Problemas ğŸ”§

Error: **"ConexiÃ³n rechazada al servidor Grobid"**

Verifica que Docker estÃ© en ejecuciÃ³n: **docker ps**

Reinicia el contenedor: **docker restart grobid**

Dependencias faltantes:

# Instalar manualmente:

**pip install wordcloud matplotlib numpy pillow**


# Estructura del Proyecto ğŸŒ³
```
â”œâ”€â”€ pdfs.zip                   # PDFs originales
â”œâ”€â”€ salida/                 # XML procesados y resultados
â”œâ”€â”€ tests/                  # test unitarios
â”œâ”€â”€ scripts/                # scripts del programa en python
â”‚   â”œâ”€â”€ procesar_pdfs.py        # Procesamiento con Grobid
â”‚   â”œâ”€â”€ generate_wordcloud.py   # Generador de nubes de palabras
â”‚   â”œâ”€â”€graficar.py             # VisualizaciÃ³n de figuras
â”‚   â”œâ”€â”€links.py                # ExtracciÃ³n de enlaces
â”œâ”€â”€ requirements.txt        # Dependencias de Python
```

# Contribuciones ğŸ‘¥

Â¡Bienvenidas las contribuciones! Sigue estos pasos:

Abre un issue describiendo la mejora.

Haz un fork del repositorio.

Crea una rama: git checkout -b mi-mejora.

EnvÃ­a un Pull Request con tus cambios.

Licencia ğŸ“œ
Distribuido bajo la licencia Apache-2.0 . Consulta el archivo **LICENSE** para mÃ¡s detalles.

**Nota:** Para procesar mÃ¡s de 10 artÃ­culos, se recomienda aumentar los recursos de Docker (RAM y CPU).
