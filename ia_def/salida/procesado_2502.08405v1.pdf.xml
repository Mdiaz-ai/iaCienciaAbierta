<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ACCELERATION OF CRYSTAL STRUCTURE RELAXATION WITH DEEP REINFORCEMENT LEARNING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2025-02-13">February 13, 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Elena</forename><surname>Trukhan</surname></persName>
							<email>elena.trukhan@skoltech.ru</email>
							<affiliation key="aff0">
								<orgName type="institution">Skolkovo Institute of Science and Technology Moscow</orgName>
								<address>
									<postCode>121205</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Efim</forename><surname>Mazhnik</surname></persName>
							<email>efim.mazhnik@skoltech.ru</email>
							<affiliation key="aff1">
								<orgName type="institution">Skolkovo Institute of Science and Technology Moscow</orgName>
								<address>
									<postCode>121205</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Artem</forename><forename type="middle">R</forename><surname>Oganov</surname></persName>
							<email>a.oganov@skoltech.ru</email>
							<affiliation key="aff2">
								<orgName type="institution">Skolkovo Institute of Science and Technology Moscow</orgName>
								<address>
									<postCode>121205</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ACCELERATION OF CRYSTAL STRUCTURE RELAXATION WITH DEEP REINFORCEMENT LEARNING</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-02-13">February 13, 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">2AFB098B97113DD40C80F3FDB6CA1C37</idno>
					<idno type="arXiv">arXiv:2502.08405v1[cond-mat.mtrl-sci]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2025-02-13T09:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce a Deep Reinforcement Learning (DRL) model for the structure relaxation of crystal materials and compare different types of neural network architectures and reinforcement learning algorithms for this purpose. Experiments are conducted on Al-Fe structures, with potential energy surfaces generated using EAM potentials. We examine the influence of parameter settings on model performance and benchmark the best-performing models against classical optimization algorithms. Additionally, the model's capacity to generalize learned interaction patterns from smaller atomic systems to more complex systems is assessed. The results demonstrate the potential of DRL models to enhance the efficiency of structure relaxation compared to classical optimizers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Structure relaxation is the optimization of the positions of atoms and the lattice geometry in the process of searching for the minimum of the potential energy and interatomic forces, which corresponds to a (meta)stable state. It is a fundamental part of atomistic and molecular modeling and is used in a wide range of scientific and engineering tasks to study the properties and behavior of various materials and systems.</p><p>Many structural relaxation algorithms formalize the problem as a function minimization task <ref type="bibr" target="#b0">[1]</ref> and search for a (meta)stable state iteratively: at each step, the potential energy, its gradients (forces), and in some methods, the Hessian matrix (stresses), are evaluated using various techniques, including first-principles methods like the density functional theory (DFT) and the Many-Body Perturbation Theory (MBPT), as well as empirical potentials, machine learning potentials, and others. The data obtained from these calculations are then used in optimization algorithms such as steepest descent <ref type="bibr" target="#b1">[2]</ref>, conjugate gradients <ref type="bibr" target="#b2">[3]</ref>, Monte Carlo <ref type="bibr" target="#b3">[4]</ref> <ref type="bibr" target="#b4">[5]</ref>, and molecular dynamics <ref type="bibr" target="#b5">[6]</ref>. These algorithms guide the shift of atoms toward the direction of minimum energy.</p><p>The issue arises when the complexity of the structure increases, such as with the growth in the number of atoms N in a unit cell or the diversity of chemical elements. This leads to an increase in the time required for relaxation, because the computational complexity of calculating the energy and forces increases with N , starting from O(N 3 ) for DFT <ref type="bibr" target="#b6">[7]</ref> up to O(N 7 ) <ref type="bibr" target="#b7">[8]</ref> <ref type="bibr" target="#b8">[9]</ref> and exp(2N ) with more accurate methods. The complexity of the potential energy surface (PES) also increases with system size, resulting in a greater number of local minima that the relaxation process must navigate <ref type="bibr" target="#b9">[10]</ref>.</p><p>Deep Reinforcement Learning (DRL) can be used in this case to predict the most efficient steps of optimization and to overcome the mentioned time problem by reducing the number of steps. In the field of material science, Reinforcement Learning has been used mainly for the design of new materials <ref type="bibr" target="#b10">[11]</ref> <ref type="bibr" target="#b11">[12]</ref>[13] <ref type="bibr" target="#b13">[14]</ref>, synthesis planning <ref type="bibr" target="#b14">[15]</ref> and microstructure optimization <ref type="bibr" target="#b15">[16]</ref> but relaxation based on RL is promising for several reasons:</p><p>• It enables the utilization of experience accumulated over a large number of optimizations, which are ignored by existing optimization methods. This is particularly beneficial because many tasks involve the relaxation of structures that have already been optimized, allowing us to leverage known paths from disturbed to relaxed structures. For example, studying the catalytic properties of a material involves the relaxation of structures that differ only in the position of several molecules on the surface.</p><p>• RL addresses the challenge of generating representative datasets, as agent gathers data directly by interacting with the environment.</p><p>• The objective of reducing the number of relaxation steps can be established both directly by selecting the reward function as a function of the number of steps and indirectly through the introduction of a discount parameter.</p><p>In the presented work, a Deep Reinforcement Learning (DRL) model for the structure relaxation process is introduced. Crystal structures are represented as crystal graphs, following the methodology of <ref type="bibr" target="#b16">Xie et al. (2018)</ref>  <ref type="bibr" target="#b16">[17]</ref>. Two types of neural networks are tested in this work: Crystal Graph Convolutional Neural Networks (CGCNN) <ref type="bibr" target="#b16">[17]</ref> and E(3)-Equivariant Tensor Field Networks <ref type="bibr">[18]</ref>. The Twin Delayed Deep Deterministic Policy Gradient (TD3) <ref type="bibr" target="#b17">[19]</ref> algorithm is primarily utilized for model training. However, we also tested the Soft Actor-Critic (SAC) <ref type="bibr" target="#b18">[20]</ref>, with results presented in Appendix G.</p><p>We compare different architectures and RL algorithms taking as a benchmark the Al-Fe system described by EAM potentials <ref type="bibr" target="#b19">[21]</ref>[22] <ref type="bibr" target="#b21">[23]</ref> used for the PES generation. First of all, dependence of the model performance on parameter settings is studied. Next, we compare the best models with classical optimizers: Broyden-Fletcher-Goldfarb-Shanno <ref type="bibr" target="#b22">[24]</ref>[25] <ref type="bibr" target="#b24">[26]</ref>[27] and Conjugate gradient <ref type="bibr" target="#b26">[28]</ref>. Finally, the model's ability to generalize learned patterns of interactions from systems with a small number of atoms/chemical elements to systems with a larger number of atoms/chemical elements is investigated.</p><p>2 Methods</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preliminary of Reinforcement Learning</head><p>Reinforcement learning (RL) is a field of machine learning applied to decision-making problems, where an Agent learns to behave in a specific Environment by performing actions and observing the outcomes. It is most commonly formulated in the form of Markov Decision Processes (MDPs). In this framework, the Agent, at a given time t in state s t , selects an action a t . This action transitions the system to the next state s t+1 , with this transition determined by the internal dynamics of the Environment, denoted as f (s ′ |s, a), which is also called transition law, so s t+1 ∼ f (•|s t , a t ). The next state s t+1 depends solely on the current state and action, thus satisfying the Markov property. Upon transitioning, the Agent receives a reward r t = R(s t , s t+1 , a t ) <ref type="bibr" target="#b27">[29]</ref>[30] <ref type="bibr" target="#b29">[31]</ref>.</p><p>The decision regarding which action to take is governed by the Agent's policy, denoted here as π. The main goal of RL is to find such a policy π * , which is called optimal, that maximizes an objective function</p><formula xml:id="formula_0">J(π) = E τ ∼π,f [R(τ )] = E τ ∼π,f T t=0 γ t r t , where γ ∈ [0, 1]</formula><p>is the discount factor and τ = (s 0 , a 0 , s 1 , a 1 , ...) is the MDP trajectory, which ends at the terminal step T . The initial state s 0 is selected randomly according to a starting distribution ρ 0 (•). The expected value is taken over the probability distribution P (τ |π) = ρ 0 (s 0 )</p><formula xml:id="formula_1">T −1 t=0 f (s t+1 |s t , a t )π(a t |s t ).</formula><p>In the context of algorithms used in this work the Agent maximizes not the objective J(π), but the action-value function Q π * (s, a). In the case of Twin Delayed DDPG (TD3) the policy π is deterministic and Q π * (s, a) is given by the formula:</p><formula xml:id="formula_2">Q π * (s, a) = E s ′ ∼P (τ |π * ) R(s, s ′ , a) + γ max a ′ Q π * (s ′ , a ′ )<label>(1)</label></formula><p>In TD3 two classes of deep learning models are introduced. The first one, called Actor, denoted as π θ (s) with tunable parameters θ, is used to approximate optimal policy π * . Another one, called Critic and denoted as Q ϕ (s, a) with tunable parameters ϕ approximates optimal action-value function Q π * (s, a). One can find more details regarding corresponding loss functions in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Crystal structure relaxation as a Markov decision process</head><p>The structure relaxation operates within a framework of Markov decision process MDP(S,A,R), where we define each term in what follows:</p><p>• S is the state space: each s t ∈ S is a crystal graph <ref type="bibr" target="#b16">[17]</ref> of the corresponding structure at time step t. In this graph, each node i represents an atom in the given unit cell and contains a node feature vector v i . The k-th edge between two nodes (i, j) k corresponds to the bond between the i-th atom and the k-th image of its j-th neighbor and contains an edge feature vector u (i,j) k .</p><p>• A is the action space: each a t ∈ A is a graph in which each node i corresponds to the node i in s t and contains the vector ∆⃗ r i , representing the atomic shift: a t = {∆⃗ r 1 , ∆⃗ r 2 , ..., ∆⃗ r N }, N is the number of atoms in a unit cell of the structure.</p><p>• R is the reward function. Four options are considered in the given work. The first one, labeled "force", optimizes atomic forces:</p><formula xml:id="formula_3">R 1 (s t , s ′ t , a t ) = − max n∈[1,N ] | ⃗ f n (s ′ t )|,<label>(2)</label></formula><p>where ⃗ f n is the force acting on the n-th atom. The second option, labeled "step", optimizes the number of steps directly:</p><formula xml:id="formula_4">R 2 (s t , s ′ t , a t ) = −1, if d t = False 0, otherwise<label>(3)</label></formula><p>where d t is a "done" flag, which is "True" when the step t is terminal and "False" otherwise. The third option, called "log force", is more sensitive to the change of atomic forces in close vicinity to the local minimum:</p><formula xml:id="formula_5">R 3 (s t , s ′ t , a t ) = − log 10 max n∈[1,N ] | ⃗ f n (s ′ t )|<label>(4)</label></formula><p>The last one, labeled "hybrid", is a composition of all functions above with some weights {w 1 , w 2 , w 3 }:</p><formula xml:id="formula_6">R 4 (s t , s ′ t , a t ) = 3 i=1 w i R i (s t , s ′ t , a t )<label>(5)</label></formula><p>• In this work, the "done" criterion for d t aligns with those commonly used in the classical algorithms:</p><formula xml:id="formula_7">d t = max n∈[1,N ] | ⃗ f n (s ′ t )| ≤ ϵ 1 ,<label>(6)</label></formula><p>where ϵ 1 is the force threshold, provided by the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Agent model implementation</head><p>The models for Actor and Critic were implemented using two types of networks: 1) Crystal Graph Convolutional Neural Networks (CGCNN) <ref type="bibr" target="#b16">[17]</ref> and 2) E(3)-Equivariant Tensor-Filed Neural Networks (TFN) for point clouds [18] <ref type="bibr" target="#b30">[32]</ref>. Both architectures handle graph-structured data using convolutional operations to aggregate information from neighboring nodes, capturing the correlation between target values and local interactions.</p><p>The main difference between them is that in CGCNN both node and edge feature vectors are treated as arrays of numbers, without distinguishing them by geometric characteristics. Consequently, it can be translation-invariant if node and edge features do not depend on absolute atomic positions and invariant to the O(3) group only if all features are scalars; otherwise, invariance and equivariance are not guaranteed.</p><p>In contrast, TFN is designed to maintain equivariance with respect to the whole E(3) group. All data in this model are treated as geometrical tensors, which are decomposed into irreducible representations of O(3). The convolutional layer is implemented as the direct product of irreducible representations, which guarantees equivariance of the architecture <ref type="bibr" target="#b31">[33]</ref>. Additional information about the neural networks and graph construction can be found in Appendix A. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Implementation of exploration</head><p>Exploration in RL is the strategy by which an Agent discovers new knowledge about its Environment, choosing actions that may not yield immediate rewards but improve future decision-making. The challenge is balancing exploration with exploitation, which involves making decisions based on the current policy.</p><p>In our work, we implement exploration in TD3 using the adding noise to state approach to preserve the symmetry of the system (a detailed discussion of the importance of this aspect in the context of RL-based structure relaxation is provided in Appendix E). For this purpose, vectors of forces in each node are rotated around randomly generated axes ⃗ n to a random angle ϕ, and the lengths of forces are modified to small values:</p><formula xml:id="formula_8">⃗ f i → (1 + ξ) • (O(⃗ n, ϕ) ⃗ f i )</formula><p>, where ξ ∼ U (−λ, λ). Here λ denotes the hyperparameter called noise level. It is important to note that forces in each node are altered with the same rotation and lengthening/shortening. Two settings for the noise parameter λ are utilized. In the first case λ is constant (λ = c), while in the second case λ varies during the training episode according to the formula λ(t) = (c 2 − c 1 )(t/L) + c 1 , where L is the maximum number of steps per episode (λ ∈ [c 1 , c 2 ]).</p><p>During the training it was observed that the TD3 algorithm with exploration, described above, tends to get stuck in states with low forces, failing to shift structures further towards a minimum (see Fig. <ref type="figure" target="#fig_0">10</ref> in Appendix F, black trajectory). The Agent converges to a policy that predicts infinitesimally small actions for such states and relaxation oscillates between the same configurations. To address this issue, we proposed to include additional greedy exploration.</p><p>In this approach greedy actions are introduced by adding noise to a state with a very high λ, to facilitate relevant exploration for the Agent. Greedy actions are sampled if</p><formula xml:id="formula_9">max n∈[1,N ] | ⃗ f n (s ′ t )| &gt; f max and max n∈[1,N ] | ⃗ ∆r n | &lt;</formula><p>∆r max for N gr steps during training, where N gr , ∆r max and f max are tunable parameters. A more detailed comparison of Agents with and without greedy exploration is provided in Appendix F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Algorithm workflow</head><p>The class for the Environment is implemented according to the standards of Gym <ref type="bibr" target="#b32">[34]</ref> Python library and constructed with Python Materials Genomics (pymatgen) <ref type="bibr" target="#b33">[35]</ref> and Atomic Simulation Environment (ASE) <ref type="bibr" target="#b34">[36]</ref> libraries.</p><p>The training loop of the RL algorithm used for structure relaxation is illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. Before initiating the training of the Agent, the structures in the provided dataset undergo relaxation with a classical algorithm, such as BFGS.</p><p>The Agent undergoes training across M train episodes, each of which lasts a maximum of N train steps. At the beginning of each episode, a crystal structure is selected from the data set and disturbed from equilibrium by introducing random distortions into the atomic coordinates: ⃗ r n (s 0 ) = ⃗ r * n + β • ⃗ ξ n , where ( ⃗ ξ n ) i ∼ U (−1, 1), ⃗ r * n are the coordinates of the n-th atom in equilibrium. Here, β is referred to as the distortion parameter. This distorted state serves as the initial point in the trajectory. Then, at each step the Agent takes actions, shifts atoms in the structure, gets the next state s ′ t and "done" flag d t , stores this transition in the storage called Replay Buffer and, if there are enough transitions in the Replay Buffer, updates Actor and Critic models. The episode ends when "done" criterion is met or when the time limit N train is reached.</p><p>Every N 1 time steps training is paused to conduct M test test episodes, each lasting maximum N test steps. The testing episodes are similar to the training ones, the only difference is that the models are not updated and the transitions are not stored in the Replay Buffer. During these test episodes, various metrics such as the cumulative full and discounted scores, maximum force at the last step max n∈[1,N ] | ⃗ f n (s T )| (further referred as maximum force) and the number of steps required for relaxation (further referred as relaxation steps) are recorded and averaged across all test episodes.</p><p>In this work N 1 = 1000, N test = 100, N train = 1000, but these parameters can be changed by the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Discussion</head><p>Considering that this is, to our knowledge, the first work where reinforcement learning is applied to the structure relaxation task, we find that it is important to provide a detailed description of how different model settings influence the algorithm's performance for further development of this approach. Accordingly, this section is structured as follows: Sections 3.1 to 3.2 cover the investigation of the method's technical aspects, while Sections 3.3 to 3.4 demonstrate the algorithm's performance on practical tasks. Additionally, an analysis of the influence of the discount factor and exploration level on model performance is provided in Appendix H.</p><p>The list of the structures in datasets and hyperparameters is provided in Appendix K.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Comparison of TFN and CGCNN models</head><p>For the comparison of two suggested architectures, the TD3 Agent was trained on CsCl-type structure of AlFe with 5 different random seeds. Averaged learning curves are presented in Fig. <ref type="figure" target="#fig_1">2</ref>. As can be seen, the CGCNN model is ineffective in performing the task of structure relaxation because it does not reduce the maximum force at the last step and does not increase the full score, as it should be in the case of successful training of RL Agent. This may be attributed to the continuous and high-dimensional nature of the task, both in terms of state and action spaces. From this perspective, the TFN model manages the task of relaxation better for two main reasons: firstly, it does not require training on augmented data to navigate through crystal structures differing only in rotations; secondly, the TFN model predicts actions not from the whole space of all possible atomic shifts, as in the case of CGCNN, but from a subspace of shifts restricted by the symmetry of the structure. It has been proven that any E(3)-equivariant model obeys Curie's principle <ref type="bibr" target="#b35">[37]</ref>, so the symmetry of the output can only be of equal or higher symmetry than the input. As a result, reducing the action space allows the model to quickly find the optimal policy. The drawback is that this feature limits our model because we cannot guarantee that geodesic path in the action space to the minimum always has higher symmetry than the symmetry of the structure. However, the investigation of this question is beyond the scope of this work.</p><p>As a result of the presented comparison, we further tested only TFN models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison of reward functions and sensitivity issues</head><p>The TD3 Agent was trained with different reward functions, outlined in Eq. ( <ref type="formula" target="#formula_3">2</ref>)-( <ref type="formula" target="#formula_5">4</ref>) on CsCl-type structure of AlFe. The results are depicted in Fig. <ref type="figure" target="#fig_2">3a-b</ref>). We also compare the performance of the best trained models with BFGS on relaxation up to higher values of the force threshold ϵ 1 (see Fig. <ref type="figure" target="#fig_2">3c</ref>).  <ref type="formula" target="#formula_3">2</ref>)-( <ref type="formula" target="#formula_5">4</ref>). The Agents were trained on CsCl-type structure of AlFe. Curves are averaged over 5 seeds, with the shaded area representing the standard deviation. Circles mark the lowest average relaxation steps and maximum force at the last step. c) Performance of the Agents, corresponding to the models with the best results with respect to relaxation steps (corresponds to the circles on b)). The plot shows the median value with an interdecile range of a sample of 50 relaxation episodes.</p><p>First of all, one can see from Fig. <ref type="figure" target="#fig_2">3c</ref>) that our models effectively relax CsCl-type structure of AlFe up to ϵ 1 = 0.1 eV/A; however, reducing the forces further is challenging. This issue may stem from insufficient model sensitivity near the minimum, as the differences in node and edge features of crystal structures approach the numerical error limits of TFN models and the spatial and angular resolution of the model architecture cannot be enough to distinguish them (see further discussions in Section D). Consequently, adopting a log force reward function has led to a reduction in the number of steps required for relaxation, indicating increased sensitivity for at least the reward function in the vicinity of the minimum.</p><p>Secondly, it can be noticed that usage of the step reward function does not provide with a better performance in terms of the number of steps required for relaxation, while from the definition of this reward function in Eq. ( <ref type="formula" target="#formula_4">3</ref>), it should optimize this value directly. This may be explained by a piecewise-constant nature of the action-value function which causes the Agent to adopt a suboptimal policy if the Agent does not face the terminal steps at the beginning of training (for the detailed discussion of this effect see Appendix C).</p><p>To address this issue we tested an approach where the Agent firstly is pretrained with more smooth functions, for example, hybrid reward with ŵ1 = 1, ŵ2 = 0, ŵ3 = 0.5 and then the reward function is switched to step with consistently reducing ϵ 1 in Eq. ( <ref type="formula" target="#formula_7">6</ref>) during training. Each stage of model training continued until the Agent reached a predetermined limit on the number of steps on relaxation.</p><p>In Fig. <ref type="figure" target="#fig_13">4a-c</ref>), a comparison is presented between the performance of a model trained exclusively on the smooth reward function and one trained on the step reward function after pretraining. This comparison is made for two cases: (1) when the Agent is trained on a single structure (the hypothetical I4/mmm structure of Al) and ( <ref type="formula" target="#formula_3">2</ref>) when it is trained on a set of multiple structures simultaneously (a dataset of monoatomic Al and Fe structures). During training with the step reward function, the parameter ϵ 1 was gradually reduced-from 0.1 eV/Å to 0.01 eV/Å for the hypothetical I4/mmm structure of Al, and from 0.1 eV/Å to 0.05 eV/Å for the dataset of monoatomic Al and Fe structures.</p><p>As shown in the results, this approach enables the model to achieve performance comparable to CG when the Agent is trained on a single structure. Furthermore, Fig. <ref type="figure" target="#fig_13">4a-b</ref>) demonstrates the model's ability to extrapolate its experience to higher distortions. Despite being trained with a distortion parameter β = 0.5, the model successfully relaxes structures with higher β values during testing. However, as illustrated in Fig. <ref type="figure" target="#fig_13">4c</ref>), this method does not guarantee improved results across all structures when the model is trained on a diverse dataset of different configurations.  <ref type="table" target="#tab_2">5</ref>). All models were trained with β = 0.5. For Al the model is tested for relaxation over a range of distortion parameter values β, displayed on the x-axis. For each point on the plots relaxation was conducted 50 times. The solid line indicates the median value with an interdecile range, while the dashed line represents the mean value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparison with classical optimizers</head><p>We compare the performance of the algorithms trained on structures with different numbers of atoms per unit cell N using the sequential approach described in Section 3.2. For N = 2 we use results on the CsCl-type structure of AlFe from the Section H and for N = 4 -the results for hypothetical I4/mmm structure of Al from the Section 3.2. For N = 8, 10, 20 the structures are generated using USPEX code <ref type="bibr" target="#b36">[38]</ref>. For each N the models are trained on a single structure and tested to perform the relaxation of the same structure but randomly distorted at the beginning of the testing episode, as described in Section 2.5. In the case of N = 2 − 8 the relaxation during training of the models and further comparison with classical algorithms are conducted up to ϵ 1 = 0.01 eV/A, while for N = 10 and N = 20 it was conducted up to ϵ 1 = 0.2 eV/A and ϵ 1 = 0.25 eV/A correspondingly due to the sensitivity issues mentioned in the Section 3.2. As one can see in Fig. <ref type="figure" target="#fig_4">5a</ref>), the results of our algorithms are similar to classical optimizers for a small number of atoms N , while for higher values of N it starts to outperform them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Generalizability of the model from simple to complex structures</head><p>An important aspect of the model that we wanted to investigate was its ability to generalize interaction patterns from small systems to more complex ones. From a physical point of view, the ordering of atoms in crystal structures (except molecular crystals) is mainly conditioned by local interactions with the closest neighbors. Therefore, we can expect that an RL Agent based on GCNN will be able to extrapolate its experience from small structures to more complex ones, as the main idea of convolution is to find the correlation between target properties and local interactions. We can expect this ability to be present in two cases:</p><p>• The number of atoms per unit cell is increased. In this case, the ability to extrapolate means that the model effectively selects the subspace of atoms that strongly influence the position of the target node in the unit cell and accounts for the fact that, in a large structure distant atoms weakly influence each other. • The chemical diversity is increased. Increasing chemical diversity leads to new types of interactions that the model needs to account for, but it can generalize these patterns from its experience with other types of interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Chemical diversity</head><p>To investigate the ability of our model to extrapolate to higher chemical diversity, the model was trained on a set of monoatomic Al and Fe structures. During testing the model performed a relaxation of CsCl-type and simple hexagonal structures of AlFe without being trained on them. The results are presented in Fig. <ref type="figure" target="#fig_4">5 b-c</ref>). As one can see, there is a strong correlation between the results for AlFe and the set of monoatomic structures, indicating that the model is able to generalize interactions between Al-Al and Fe-Fe to the case of Al-Fe interactions. The best result for the model, presented in Fig. <ref type="figure" target="#fig_4">5c</ref>), in the case of CsCl-type structure of AlFe relaxation is 11.3 ± 7.6 steps, which is close to the best results of the model trained solely on this configuration (see Fig. <ref type="figure" target="#fig_11">12a</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Number of atoms per unit cell</head><p>To investigate the ability of our model to extrapolate to a higher number of atoms per unit cell, we test how the models trained on single structures with different number of atoms per unit cell relax the corresponding supercells 2 × 1 × 1 and 2 × 2 × 1 without being trained on them. The results are presented in Fig. <ref type="figure" target="#fig_5">6</ref>.</p><p>As expected, increasing the number of atoms in the structures in the training dataset led to better extrapolation to larger configurations. Consequently, we can anticipate that at some point, the model will be able to relax large structures without being pretrained on them. This is because the Agent will be capable of selecting the corresponding subspace for each atom and predicting its atomic shift based on the experience gained from relaxing smaller structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Cumulative generalizability</head><p>In this section, we assess the applicability of algorithms for more practical tasks. Specifically, we focus on training the model on simpler structures and subsequently use it to relax more complex structures, which are larger and have new types of chemical bonds.</p><p>We use three datasets of Al-Fe structures with varying compositions generated using USPEX software. The first dataset consists of 20 structures, each containing 2-3 atoms per unit cell, and it is used to train the model. During the training   In the middle plot of Fig. <ref type="figure" target="#fig_6">7</ref>, we observe that, on average, the normalized last step slightly changes after ϵ 1 = 0.3 eV/A. This could be related to instability in the RL model, which is also reflected in the maximum force at the last step, as shown in the left plot of Fig. <ref type="figure" target="#fig_6">7</ref>. The maximum force gradually decreases with the reduction of ϵ 1 , approaching ϵ 1 as training progresses until it reaches ϵ 1 = 0.2 eV/A. At this point, sharp peaks are observed, indicating possible instability due to a low sensitivity near the minimum discussed earlier. Because of this issue, switching to the step reward function, as discussed in Section 3.2, did not improve the model, and thus, we do not provide the results for this reward function here.</p><p>Regarding the model's generalizability, there is a strong correlation between the results for N = 2 − 3 and N = 4 − 5 as shown in Fig. <ref type="figure" target="#fig_6">7</ref>. This indicates that our model can be applied to relax more complex structures without pre-training on them. However, the fraction of relaxed structures for reasonable values of ϵ 1 (approximately 0.1 eV/A) ranges from 0.1 to 0.4, which is not a sufficient outcome.</p><p>There are two primary reasons for this. The first reason, discussed in Section 3.4.2, is that the model needs to be trained on larger structures to efficiently identify the subspace of the most important neighbors for a given atom. The second reason is that not all interaction and symmetry patterns in structures with 4 − 5 atoms per unit cell are present in structures with N = 2 − 3 atoms per unit cell. A possible solution would be to incorporate an active learning approach, sequentially adding structures with higher N until the model is sufficiently trained to relax large structures. However, this approach is outside the scope of this study due to computational costs and may be considered in future research.</p><p>These findings illustrate the potential for crystal structure relaxation using deep reinforcement learning. Overcoming the mentioned challenges could lead to a universal structure optimizer that is faster for large configurations than traditional optimizers. Nonetheless, achieving this goal requires further development and additional computational resources for model training.</p><p>Our work underscores several critical aspects of reinforcement learning. Firstly, we highlight the importance of symmetry preservation in the action space for effective model training. We show that TFN model is more suitable to structure relaxation tasks compared to CGCNN, as it limits predicted actions to spaces with the same or higher symmetry than the input structure. Secondly, we point out the limitations of training with a piecewise-constant action-value function using a step reward function. Direct optimization of the number of steps with this function is challenging, as the model may converge to a suboptimal policy due to a feedback loop of Critic and Actor convergence caused by the piecewise-constant nature of the true Q-function. However, pretraining the agent on smoother reward functions, such as force or hybrid, can mitigate this issue by increasing the likelihood of reaching terminal states early in training, a crucial condition for converging to an optimal policy.</p><p>Our study extensively examines the space of model hyperparameters and their impact on performance. We determined that simultaneous tuning of the discount factor and noise level enables the Agent to explore efficiently while balancing short-and long-term rewards to develop an optimal policy. Additionally, we investigated the influence of different reward functions, identifying the best way to combine them to maximize benefits across training epochs.</p><p>We compared various RL algorithms and found that TD3 is more efficient than SAC for structure relaxation tasks. However, this efficiency might be linked to exploration limitations in our SAC implementation. Future research will continue comparing different architectures and implementations of SAC and TD3 policies.</p><p>We hope our findings lay a foundation for further advancements in using reinforcement learning for structure relaxation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A Graph neural networks A.1 Irreducible representations</head><p>In this work, TFN models are implemented using the e3nn <ref type="bibr" target="#b31">[33]</ref> Python library. Within the e3nn framework, all input tensors are decomposed into the irreducible representations of the group O(3), which are labeled by the degree l = 0, 1, 2, 3, . . . and parity p ∈ (1, −1). When p = 1 the representation is called "even", otherwise, it is called "odd". For example, in general, 3 × 3 matrix A can be decomposed into a scalar (l = 0, p = 1), pseudovector (l = 1, p = 1) and even 2-nd order representations (l = 2, p = 1). In the e3nn notation A can be represented as</p><formula xml:id="formula_10">A = 1 × 0e + 1 × 1e + 1 × 2e.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Convolutional operation</head><p>The convolution operation in CGCNN is defined as follows <ref type="bibr" target="#b16">[17]</ref>:</p><formula xml:id="formula_11">v (t+1) i = v (t) i + j,k σ(z (t) (i,j) k W (t) f + b (t) f ) ⊙ g(z (t) (i,j) k W (t) s + b (t) s ),<label>(7)</label></formula><p>where</p><formula xml:id="formula_12">z (t) (i,j) k = v (t) i ⊕ v (t) j ⊕ u (i,j) k , ⊕ denotes concatenation of vectors, ⊙ denotes element-wise multiplication, σ represents a sigmoid function, W (t) f , W (t)</formula><p>s are the convolution weight matrices, b</p><formula xml:id="formula_13">(t) f , b (t)</formula><p>s are the biases, g is an activation function.</p><p>In e3nn <ref type="bibr" target="#b31">[33]</ref> the convolutional operation on node a is implemented as the direct product of irreducible representations and can be written as: (li,mi)(l f ,m f ) are Clebsch-Gordan coefficients. In Eq. ( <ref type="formula" target="#formula_14">8</ref>) R(r ij ) is a rotationally invariant radial function that contains all learnable weights. It is implemented as a multi-layer perception R(r ij ) = W n σ(....σ(W 2 σ(W 1 B(r ij ))), where B(r ij ) denotes the embedding of the interatomic distance of dimension N b , W i are weight matrices and σ(x) is the nonlinear function. In the given work the following embedding was used:</p><formula xml:id="formula_14">L (lo,po,l f ,p f ,li,pi) acmo ⃗ r a , V (li,pi) acmi = m f ,mi C (lo,mo) (li,mi)(l f ,m f ) b∈S R(r ab ) (l f ,li,p f ,pi) c Y (l f ) m f (r ab )V (li,pi) bcmi ,<label>(8)</label></formula><formula xml:id="formula_15">B(r) = exp − r − (a + s • i) s 2 N i=1 ,<label>(9)</label></formula><p>where s = b−a N b , a and b are the minimum and maximum value span by the basis respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Graph construction</head><p>During the conversion of crystal structures into crystal graphs, we use the following features for nodes and edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.1 Node features</head><p>• Scalar features: atomic number, standard atomic weight, Pauling electronegativity, atomic radius (pm), covalent radius (pm), first ionization energy (kJ/mol), electron affinity (kJ/mol), atomic volume (A 3 ), polarizability, number of electrons in the outermost shell, boiling point (K), specific heat capacity (J/gK). All scalar features are normalized. In terms of e3nn notation, these features correspond to 12 × 0e. • Vector features: force that acts on the atom, calculated with chosen potential (eV/A). As a vector, this feature corresponds to the 1 × 1o irreducible representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.2 Edge features</head><p>Edge feature vector contained interatomic vectors ⃗ r ij = ⃗ r i − ⃗ r j , which are then used for the embedding according to the rule in Eq. ( <ref type="formula" target="#formula_15">9</ref>). In the given work N b =10, a = 0A, b = 5A. To determine the neighbors for each node, a sphere with a given radius r max = 5A and centered at the location of the atom is considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B Twin delayed DDPG loss functions</head><p>TD3 algorithm represents an enhanced version of Deep Deterministic Policy Gradient (DDPG) <ref type="bibr" target="#b37">[39]</ref>. DDPG is based on the Bellman optimality equation in Eq. ( <ref type="formula" target="#formula_2">1</ref>) and idea, that if optimal action-value function is know, optimal actions can be found as a * (s) = argmax a Q * (s, a) <ref type="bibr" target="#b17">[19]</ref>.</p><p>So the loss function for π θ (s) is obtained from the definition:</p><formula xml:id="formula_16">L T D3 θ = −E s∼D Q ϕ1 (s, π θ (s)) ,<label>(10)</label></formula><p>In Eq. ( <ref type="formula" target="#formula_16">10</ref>) one can observe the index in parameters ϕ. The reason for this is that in TD3, two Q-functions, denoted as Q ϕ1 and Q ϕ2 , are used to mitigate the overestimation of the real Q-function, that was observed in DDPG algorithm. Additionally, one may notice that the expected value, present in all the equations mentioned above, is replaced by the averaging over transitions (s, s ′ , a, d, r) sampled from a storage container D referred to as the Replay buffer. This buffer is of limited size and contains the experience gathered by the Agent during simulations.</p><p>The loss function for Q ϕi is known as the mean-squared Bellman error (MSBE), because it is derived from Eq. ( <ref type="formula" target="#formula_2">1</ref>) as follows:</p><formula xml:id="formula_17">L T D3 ϕi=1,2 = E (s,a,r,s ′ ,d)∼D Q ϕi=1,2 (s, a) − r(s, a) + γ(1 − d) min i=1,2 Q ϕi,targ (s ′ , π θtarg (s ′ )) ,<label>(11)</label></formula><p>where Q ϕi,targ and π θtarg are target models. They are introduced to make target values in the loss function independent on the model parameters ϕ i=1,2 and θ, thereby stabilizing the model update process. Unlike conventional models, the parameters of the target models do not get updated through gradient descent but change according to the following rule:</p><formula xml:id="formula_18">ω targ = ρω targ + (1 − ρ)ω, ω = {ϕ 1 , ϕ 2 , θ}<label>(12)</label></formula><p>where ρ ∈ [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C Discussion of the step reward function</head><p>As it was mentioned in Section 3.2, a straightforward use of the step reward function does not lead to the better performance in terms of the number of steps required for relaxation, which is to be expected according to the definition of this reward.</p><p>This can be partly explained by the findings of <ref type="bibr" target="#b38">[40]</ref>, which investigates the failures of the TD3 algorithm in deterministic environments with sparse rewards, which is a type of reward that assigns a value of 0 for all transitions except terminal ones. In such cases the TD3 Agent tends to converge to a suboptimal policy if it does not encounter any non-zero rewards at the beginning of training because of the piecewise-constant nature of the true action-value function Q π corresponding to a poor policy which leads to gradients ∇ θ Q(s, π θ (s)) ≃ 0 and causes a closed loop of zero updates for both the Critic and the Actor.</p><p>While the reward function step is not sparse, it is intuitively clear (see Section 2.1) that its action-value function is also piecewise-constant. To demostrate that let's consider a "good" policy π, which, starting in the given state s 0 and taking action a 0 , reaches the terminal state in n steps ("good" in comparison to the policy that never allows the Agent to achieve the terminal state). Its Q-function is given by:</p><formula xml:id="formula_19">Q π (s 0 , a 0 ) = R(τ ) = n−1 t=0 (−1) • γ t + 0 = − γ n − 1 γ − 1 (<label>13</label></formula><formula xml:id="formula_20">)</formula><p>where γ is the discount factor.</p><p>We can see that for a "good" policy, the function domain of Q π (s 0 , a 0 ) is partitioned into regions with identical values, as determined by Eq. ( <ref type="formula" target="#formula_19">13</ref>). Consequently, even for a "good" policy, the converged action-value function remains piecewise-constant, and it is true for both noise settings. The crucial distinction between them lies in the fact that adding noise to action diminishes the probability of reaching the terminal state during training by disrupting the symmetry of actions and removing them from the space of actions relevant for the given structure, as discussed earlier. This aligns with findings in <ref type="bibr" target="#b38">[40]</ref>, where delayed discovery of the initial reward often leads to the learning process becoming stuck in a sub-optimal policy due to the closed loop problem described above. This scenario applies to our task, as the absence of encounters with the terminal state may lead the Agent to consider the sum in Eq. ( <ref type="formula" target="#formula_19">13</ref>) for each action-state (s, a) pair as infinite, resulting in a constant value of Q π (s, a) = 1 γ−1 for all action-state pairs, resembling the situation described in <ref type="bibr" target="#b38">[40]</ref>. As a result, it is crucial to provide the Agent with exhausting experience in the vicinity of the terminal step in the beginning of training before convergence of the models. However, this explanation remains unverified in our study but it could be a subject of investigation in the future.  <ref type="formula" target="#formula_3">2</ref>)-( <ref type="formula" target="#formula_5">4</ref>) with adding noise to action exploration stratagy. The Agents were trained on CsCl-type structure of AlFe. Curves are averaged over 5 seeds, with the shaded area representing the standard deviation. Circles mark the lowest average last step and maximum force.</p><p>In this study, we implemented an alternative approach to exploration for TD3 algorithm by adding noise to action. In this case, small uniformly distributed noise is added independently to each coordinate, (∆⃗ r i ) j → (∆⃗ r i ) j + ξ ij , where ξ ij ∼ U (−λ, λ), and λ represents the noise level.</p><p>To evaluate this approach, we compared it with the adding noise to state method by training the TD3 Agent with different noise settings on the CsCl-type structure of AlFe. The results for adding noise to action are shown in Fig. <ref type="figure" target="#fig_9">9</ref> and the comparison is summarized in Table <ref type="table">2</ref>.</p><p>Table <ref type="table">2</ref>: The best results achieved by the TD3 Agents with different reward functions and noise settings. Average indicates the lowest maximum force and relaxation steps from the averaged learning curves, marked by circles in Fig. <ref type="figure" target="#fig_2">3a-b</ref>) and Fig. <ref type="figure" target="#fig_9">9</ref>. The best results over all trials represents the top-performing outcomes across all seeds used for averaging. The lowest-performing maximum force and relaxation steps are highlighted. The comparison clearly shows that, for all reward functions, adding noise to state consistently outperforms adding noise to action. This highlights the importance of preserving symmetry in RL tasks, as previously discussed. Adding noise to output vectors disrupts the symmetry encoded in the TFN model. As a result, this exploration strategy fails to provide relevant experiences for the Agent, because, firstly, due to Curie's principle, the model cannot replicate such actions, and secondly, these actions may not even fall within the subspace of atomic shifts relevant to the structure due to its symmetry. Conversely, adding noise to state, as implemented in this study, successfully avoids these issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noise</head><p>The most pronounced difference is observed with the step reward function due to the convergence issues discussed in Section 3.2 and Appendix C. Adding noise to actions reduces the probability of reaching the minimum using the initial suboptimal policy and leads to convergence loops, as described in Appendix C.</p><p>These findings further underscore the advantage of restricting the possible actions to align with the task's symmetry, thereby enhancing model performance. where a ′ ∼ π θ (•|s ′ ).</p><p>Since the deep model cannot directly predict the probability density function, it is assumed that π θ ∼ N (µ θ , σ θ ).</p><p>Consequently, the model approximates the expectation value µ θ and variance σ θ of the normal distribution. In this scenario, the loss for the policy takes the following form:</p><formula xml:id="formula_21">L SAC θ = −E s∼D,ξ∼N (0,I) min i=1,2 Q ϕi (s, a θ (s, ξ)) − α log π θ (a θ (s, ξ)|s) ,<label>(16)</label></formula><p>where a θ (s, ξ) = µ θ (s) + σ θ ⊙ ξ, ξ ∼ N (0, I).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.1.1 Implementation of exploration</head><p>In SAC exploration is inherently incorporated through entropy regularization. The policy is stochastic and given by the probability distribution π(a|s) = P (a|s), a t ∼ π(•|s t ). Since the deep model cannot directly predict PDF, it is assumed that π θ ∼ N (µ θ , σ θ ), where in a general case µ θ is k-dimensional mean vector and σ θ is k × k covariance matrix. Consequently, the model approximates µ θ and σ θ .</p><p>However, in the given task a challenge arises because a t is a graph, containing atomic shifts. Approximating the optimal policy with a set of independent normal distributions for each vector would hardly provide sufficient Agent performance, as these values are connected by various relationships, such as E(3)-equivariance or symmetry constraints of the structure.</p><p>The solution presented in this work is to introduce stochasticity solely to the norm of the vectors. In this approach, the model predicts a graph where each node contains a vector ⃗ µ i and a scalar σ i . Then expectation values |⃗ µ i | and unit direction vectors</p><formula xml:id="formula_22">⃗ n i = ⃗ µ i /|⃗ µ i | are computed, normal distribution N (|⃗ µ i |, σ i ) is constructed for each node, and the magnitude |∆⃗ r i | is sampled as |∆⃗ r i | ∼ N (|⃗ µ i |, σ i ).</formula><p>The atomic shift for the i-th atom is then obtained as ∆⃗ r i = |∆⃗ r i | • ⃗ n i . This approach ensures compliance with the norm distribution constraint under rotation and preserves the correlations between shift directions detected by the model. However, it restricts the Agent's exploration capabilities, as stochasticity is only introduced to the shift lengths. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.1.2 Hyperparameters exploration and comparison with TD3</head><p>Similarly to TD3 we investigated the influence of the discount factor and exploration level on the performance model, using CsCl-type structure of AlFe, but the main difference is that in the case of SAC exploration is controlled by the trade-off parameter α. Results of the tests are presented in Fig. <ref type="figure" target="#fig_11">12b</ref>) and more detailed comparison of learning curves is also shown in Fig. <ref type="figure" target="#fig_14">15</ref>.</p><p>As it can be seen, for SAC the best performance correspond to the model trained with the smallest γ factor and α, which proves the assumption, derived in Appendix H that a lower discount factor with small exploration allows the model to concentrate on the immediate slightly noised outcome and build in this way efficient policy.</p><p>As for comparison of TD3 and SAC, it can be seen over the range of hyperparameters that TD3 outperforms SAC in number of steps required for relaxation, so that is the reason why TD3 is used mainly in the given work. The possible reason might be that policy implementation, described in Section G.1.1, does not provide the Agent with exhaustive exploration, because it is limited only to stochasticity in the norm of atomic shifts ∆⃗ r i , but does not cover their directions. So further improvement of the model is needed to increase the quality of the algorithm.      <ref type="table">6</ref>: Hyperparameters, used in the given work. Here F, ST, LF, and H denote force, step, log force, and hybrid reward function settings correspondingly. In the case of hybrid reward function weights, introduced in Eq. ( <ref type="formula" target="#formula_6">5</ref>), were always w 1 = 1, w 2 = 0, w 3 = 0.5. Noise stands for noise level λ in the case of TD3 algorithm and for trade-off coefficient α in the case of SAC algorithms. The Dataset row lists the structure numbers from the Table <ref type="table" target="#tab_2">5</ref>  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Workflow of the Reinforcement Learning algorithm used for structure relaxation.</figDesc><graphic coords="4,72.00,72.00,467.97,236.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Learning curves of TD3 Agents with CGCNN and TFN architectures, trained on CsCl-type structure of AlFe. Curves are averaged over 5 trials with different random seeds, with the shaded area representing half a standard deviation.</figDesc><graphic coords="5,72.00,416.10,468.01,253.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: a) -b) Learning curves of TD3 Agents with different reward functions, given by Eq. (2)-(4). The Agents were trained on CsCl-type structure of AlFe. Curves are averaged over 5 seeds, with the shaded area representing the standard deviation. Circles mark the lowest average relaxation steps and maximum force at the last step. c) Performance of the Agents, corresponding to the models with the best results with respect to relaxation steps (corresponds to the circles on b)). The plot shows the median value with an interdecile range of a sample of 50 relaxation episodes.</figDesc><graphic coords="6,72.00,295.99,467.99,156.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comparison of classical algorithms and TD3 Agents trained with and without switching to the step reward after pertaining a) with hybrid reward function ( ŵ1 = 1, ŵ2 = 0, ŵ3 = 0.5) on hypothetical I4/mmm structure of Al b) with force reward function on the set of monoatomic Al and Fe structures (the description of the set is presented in Table5). All models were trained with β = 0.5. For Al the model is tested for relaxation over a range of distortion parameter values β, displayed on the x-axis. For each point on the plots relaxation was conducted 50 times. The solid line indicates the median value with an interdecile range, while the dashed line represents the mean value.</figDesc><graphic coords="7,72.00,216.83,467.99,156.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: a) Comparison of TD3 model and classical optimizers in relaxation of structures with different number of atoms N in the unit cell. For N = 2 − 8 the relaxation was conducted up to ϵ 1 = 0.01 eV/A, while for N = 10 and N = 20 up to ϵ 1 = 0.2 eV/A and ϵ 1 = 0.25 eV/A correspondingly. For each point on the plot, relaxation was conducted 50 times. The solid line indicates the median value with an interdecile range, while the dashed line represents the mean value. b-c) Learning curve of the TD3 model, trained on the set of monoatomic Al and Fe structures with force reward function (black) and its performance on CsCl-type (red) and simple hexagonal (blue) structures of AlFe during test. The shaded region represents a standard deviation of the average evaluation over 2 trials.</figDesc><graphic coords="8,72.00,214.35,467.99,156.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Number of steps required for relaxation of supercells by TD3 Agents trained on structures with different number of atoms N in the unit cell. Performance is measured for different ϵ 1 values, displayed on the x-axis. The y-axis represents the number of steps taken by the optimizer for the relaxation of the structure, averaged over 50 runs. The solid line indicates the median value with an interdecile range, while the dashed line represents the mean value.It should be noticed that in the case of N = 20 the model was trained to perform the relaxation up to ϵ 1 = 0.25 eV/A and for N = 10 up to ϵ 1 = 0.2 eV/A, as it is mentioned in the Section 3.3.</figDesc><graphic coords="9,72.00,72.00,468.00,114.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Learning curve of the TD3 model, trained on random Al and Fe configurations with N = 2 − 3 (black line) and validated on configurations with N = 4 (red dots) and N = 5 (blue triangles). We implemented a sequential decrease of the ϵ 1 parameter, as described in Section 3.2, along with a hybrid reward function. The corresponding ϵ 1 values are shown on the upper axis. In every testing episode, the model was validated on datasets containing structures with N = 4 and N = 5 atoms per unit cell. For each structure, we performed 5 relaxation episodes, each starting with different initial distortions from the minimum. There were 50 structures for each N (refer to Section J). In the left plot, the maximum force at the last step, averaged over 20 relaxation episodes (1 per structure in the training dataset), is presented. The shaded area represents the standard deviation. The middle plot shows the normalized last step value n • ϵ 1 for both training and validation datasets, averaged over 20 relaxation episodes for the training dataset (1 per structure) and 250 episodes for each validation dataset (5 episodes per structure). The right plot illustrates the fraction of successful relaxation episodes out of the total number of relaxation episodes.To evaluate changes in the quality of the model's performance for different values of ϵ 1 , We use a concept of normalized last step, where the number of relaxation steps is multiplied by the force threshold to compensate for the increased difficulty as epsilon decreases. It allows to show the overall improvement of the relaxation algorithm and to compare the values between different ϵ 1 -regions.</figDesc><graphic coords="9,72.00,348.45,467.99,178.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Table 1 : 4 Fig. N = 5</head><label>145</label><figDesc>Number of relaxation steps up to forces 0.2 eV/A in the end of model training in Fig. 7. In the table mean values with standard deviation are presented. For N = 2 − 3 the sample consisted of 20 relaxation episodes (1 per structure), for N = 4 and N = 5 it consisted of 250 episodes for each validation dataset (5 episodes per structure). N = 2 − 3 N = Relaxation steps 17.3 ± 5.8 73.1 ± 39.5 97.3 ± 12.8</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>where a and b index the central atom being convolved and a neighboring atom respectively, S represents graph nodes, c corresponds to the channel. Each channel denotes a different instance of an irreducible representation. V (li,pi) bcmi is the m i -th component of the b-node feature in the c-th channel, which corresponds to the irreducible representation of O(3) group with degree l i and parity p i . Y (l f ) m f represents spherical harmonics of degree l f and order m f . ⃗ r a represents the position of the a-th atom in the point cloud, while ⃗ r ab denotes the relative position from central atom a to neighboring atom b, r ab = |⃗ r ab |, rab = ⃗ r ab /r ab . C (lo,mo)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Learning curves of TD3 Agents with different reward functions, given by Eq. (2)-(4) with adding noise to action exploration stratagy. The Agents were trained on CsCl-type structure of AlFe. Curves are averaged over 5 seeds, with the shaded area representing the standard deviation. Circles mark the lowest average last step and maximum force.</figDesc><graphic coords="15,72.00,72.00,467.99,156.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Comparison of TD3 Agents trained with ("Greedy (force)" and "Greedy (hybrid)") and without ("Ordinary") greedy exploration on a-c) the set of Al and Fe structures listed in Table 5 d-f) hypothetical I4/mmm structure of Al with 4 atoms per unit cell. The bold lines represent the learning curve averaged over 2 trials with different random seeds and shaded regions show corresponding standard deviation.</figDesc><graphic coords="17,72.00,72.00,467.99,222.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Performance of the best in terms of relaxation steps of TD3 and SAC models (marked with circles in Fig. 13b,e,h) and Fig. 15b,e,h). The Agents were trained with different discount factors γ and level of exploration on CsCl-type structure of AlFe. The figure shows the mean value with standard deviation averaged over 10 relaxation test episodes.</figDesc><graphic coords="18,72.00,72.00,467.99,156.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: Learning curves comparing the performance of TD3 Agents with different discount factors γ. The Agents were trained on CsCl-type structure of AlFe with a log force reward function and a distortion parameter β = 0.5. Curves are averaged over 5 seeds, with the shaded area representing the standard deviation across seeds. Circles mark the lowest average number of relaxation steps and maximum force, as well as the highest score.</figDesc><graphic coords="20,72.00,72.00,467.99,111.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Table 4 :</head><label>4</label><figDesc>The best results of the SAC Agents with different discount factors γ and entropy trade-off coefficients α. Average corresponds to the highest score and the lowest maximum force and number of relaxation steps of the averaged learning curves, marked with circles in Fig.15. Best represents the top-performing results among all seeds used for averaging. The highest scores and the lowest maximum force and number of relaxation steps are highlighted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15: Learning curves comparing the performance of SAC Agents with different discount factors γ and entropy trade-off coefficients α: a-c) γ = 0.9, d-f) γ = 0.99, g-i) γ = 0.9999. The Agents were trained on CsCl-type structure of AlFe with force reward function and a distortion parameter of β = 0.5. Curves are averaged over 3 seeds, with the shaded area representing the standard deviation across seeds. Circles mark the lowest average number of relaxation steps and maximum force, as well as the highest score.</figDesc><graphic coords="21,72.00,72.00,467.99,334.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="14,72.00,354.04,468.00,193.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="19,72.00,143.13,467.99,334.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 5 :</head><label>5</label><figDesc>Structures used for model training. Here N is the number of atoms in initial unit cell. During training structures with N = 1 are doubled so 2 × 1 × 1 supercell is relaxed. Table</figDesc><table><row><cell></cell><cell>Dataset</cell><cell>Structures</cell><cell>Materials Project ID</cell><cell>N</cell><cell>EAM</cell></row><row><cell>0</cell><cell></cell><cell>alpha-U-type (Cmcm) Fe</cell><cell>mp-1271128</cell><cell>2</cell><cell></cell></row><row><cell>1</cell><cell></cell><cell>b.c.c. Fe</cell><cell>mp-13</cell><cell>2</cell><cell></cell></row><row><cell>2</cell><cell></cell><cell>I4/mmm-distorted b.c.c Fe</cell><cell>mp-1271068</cell><cell>4</cell><cell></cell></row><row><cell>3</cell><cell></cell><cell>Simple hexagonal Fe</cell><cell>mp-1096950</cell><cell>1</cell><cell>[21]</cell></row><row><cell>4</cell><cell></cell><cell>h.c.p Fe</cell><cell>mp-136</cell><cell>2</cell><cell></cell></row><row><cell>5</cell><cell>Monoatomic</cell><cell>hypothetical I4/mmm Fe</cell><cell>mp-1271198</cell><cell>4</cell><cell></cell></row><row><cell>6</cell><cell>Al and Fe</cell><cell>f.c.c. Fe</cell><cell>mp-150</cell><cell>1</cell><cell></cell></row><row><cell>7</cell><cell></cell><cell>h.c.p. Al</cell><cell>mp-2647008</cell><cell>2</cell><cell></cell></row><row><cell>8</cell><cell></cell><cell>hypothetical I4/mmm Al</cell><cell>mp-1239196</cell><cell>4</cell><cell></cell></row><row><cell>9</cell><cell></cell><cell>Al</cell><cell>mp-998860</cell><cell>1</cell><cell>[22]</cell></row><row><cell>10</cell><cell></cell><cell>double h.c.p Al</cell><cell>mp-1183144</cell><cell>4</cell><cell></cell></row><row><cell>11</cell><cell></cell><cell>f.c.c. Al</cell><cell>mp-134</cell><cell>1</cell><cell></cell></row><row><cell>12</cell><cell></cell><cell>CsCl-type AlFe</cell><cell>mp-2658</cell><cell>2</cell><cell>[23]</cell></row><row><cell>13</cell><cell></cell><cell>hexagonal AlFe</cell><cell>mp-985578</cell><cell>2</cell><cell></cell></row><row><cell>14</cell><cell></cell><cell>AlFe 7</cell><cell>-</cell><cell>8</cell><cell>[23]</cell></row><row><cell>15</cell><cell></cell><cell>Al 8 Fe 2</cell><cell>-</cell><cell>10</cell><cell>[23]</cell></row><row><cell>16</cell><cell></cell><cell>Al 2 Fe 18</cell><cell>-</cell><cell>20</cell><cell>[23]</cell></row><row><cell>17</cell><cell>Al-Fe compounds with N = 2 − 3</cell><cell>-</cell><cell>-</cell><cell cols="2">2-3 [21][23][22]</cell></row><row><cell>18</cell><cell>Al-Fe compounds with N = 4</cell><cell>-</cell><cell>-</cell><cell>4</cell><cell>[21][23][22]</cell></row><row><cell>19</cell><cell>Al-Fe compounds with N = 5</cell><cell>-</cell><cell>-</cell><cell>5</cell><cell>[21][23][22]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Nathaniel Thomas, Tess Smidt, Steven Kearnes, Lusann Yang, Li Li, Kai Kohlhoff, and Patrick Riley. Tensor field networks: Rotation-and translation-equivariant neural networks for 3D point clouds. arXiv preprint, 2018.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>used for the</cell></row><row><cell>input dataset.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Parameter</cell><cell>Fig. 2</cell><cell>Fig. 3, Fig. 9</cell><cell>Fig. 4a)</cell><cell>Fig. 4b)</cell></row><row><cell>γ</cell><cell>0.99</cell><cell>0.9 (F, ST), 0.5 (LF)</cell><cell>0.9999</cell><cell>0.9999</cell></row><row><cell>Noise</cell><cell>[10 −2 , 10 −3 ]</cell><cell>[10 −2 , 10 −3 ]</cell><cell>0.2</cell><cell>0.2</cell></row><row><cell>Reward</cell><cell>F</cell><cell>F, ST, LF</cell><cell>H, H + ST</cell><cell>F, F + ST</cell></row><row><cell>ϵ 1 , eV/A</cell><cell>10 −6</cell><cell>10 −4</cell><cell>10 −2</cell><cell>10 −1</cell></row><row><cell>Dataset</cell><cell>#12</cell><cell>#12</cell><cell>#8</cell><cell>#0-11</cell></row><row><cell></cell><cell>Fig. 5b-c)</cell><cell>Fig. 5a)</cell><cell>Fig. 6</cell><cell>Fig. 7</cell></row><row><cell>γ</cell><cell>0.9999</cell><cell>0.9999</cell><cell>0.9999</cell><cell>0.9999</cell></row><row><cell>Noise</cell><cell>0.2</cell><cell>0.2</cell><cell>0.2</cell><cell>0.2</cell></row><row><cell>Reward</cell><cell>F</cell><cell>F, H + ST</cell><cell>H + ST</cell><cell>H</cell></row><row><cell>ϵ 1 , eV/A</cell><cell>10 −2</cell><cell>10 −2 , 0.2, 0.25</cell><cell>10 −2 , 0.2, 0.25</cell><cell>-</cell></row><row><cell>Dataset</cell><cell>#0-11</cell><cell>#12, #8, #14-16</cell><cell>#8, #14-16</cell><cell>#17-19</cell></row><row><cell></cell><cell>Fig. 8</cell><cell>Fig. 11a-c)</cell><cell>Fig. 11d-f)</cell><cell>Fig. 12</cell></row><row><cell>γ</cell><cell>0.9999</cell><cell>0.9999</cell><cell>0.9999</cell><cell>-</cell></row><row><cell>Noise</cell><cell>0.2</cell><cell>0.2</cell><cell>0.2</cell><cell>-</cell></row><row><cell>Reward</cell><cell>H</cell><cell>F</cell><cell>H, F</cell><cell>F</cell></row><row><cell>ϵ 1 , eV/A</cell><cell>0.2</cell><cell>10 −1</cell><cell>10 −2</cell><cell>10 −2</cell></row><row><cell>Dataset</cell><cell>#18</cell><cell>#0-11</cell><cell>#8</cell><cell>#12</cell></row><row><cell></cell><cell>Fig. 13</cell><cell>Fig. 14</cell><cell>Fig. 15</cell><cell></cell></row><row><cell>γ</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell></row><row><cell>Noise</cell><cell>-</cell><cell>[0.01, 0.001]</cell><cell>-</cell><cell></cell></row><row><cell>Reward</cell><cell>F</cell><cell>LF</cell><cell>F</cell><cell></cell></row><row><cell>ϵ 1 , eV/A</cell><cell>10 −2</cell><cell>10 −4</cell><cell>10 −2</cell><cell></cell></row><row><cell>Dataset</cell><cell>#12</cell><cell>#12</cell><cell>#12</cell><cell></cell></row><row><cell>[18]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>arXiv:1802.08219.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0">ConclusionsIt has been demonstrated that the TD3 model, when trained on a single structure, performs comparably or even better than classical algorithms such as BFGS and CG, especially in the range of force convergence up to approximately ϵ 1 ∼ 10 −1 − 10 −2 eV/Å. However, achieving convergence to lower force values or training on several structures simultaneously remains challenging due to the sensitivity issues of the TFN model near minima. Despite this, relaxation to forces below 10 −1 − 10 −2 eV/Å is not critically problematic in practice. A hybrid approach can be employed: after reaching this force range, one can switch to classical algorithms, which can quickly reach a minimum since the potential energy surface (PES) in this region is close to a parabolic function. As a result, the current limitations discourage using this method as a universal optimizer. However, it is well-suited for tasks involving the relaxation of identical structures from different unstable initial states, such as in catalysis. In this case, the algorithm can be used as a baseline optimizer for commonly used systems.We also explored the model's generalization capabilities from simple to complex structures. Initially, we assessed the model's performance as the number of atoms per unit cell increased. Results indicated that the model effectively relaxes supercells of similar structures, with performance improving as the size of the input structure in the training dataset increases. We anticipate that the model will eventually be capable of relaxing large structures without prior training on them, as the Agent will identify relevant subspaces for each atom and predict their atomic shifts based on experience gained from smaller structures. In addition, we found that the model can extrapolate its experience to cases where the complexity of chemical bonds increases.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The calculations were performed on the Zhores cluster at Skolkovo Institute of Science and Technology.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declarations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Funding</head><p>This work was supported by the Russian Science Foundation (grant #19-72-30043).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Conflict of interest/Competing interests</head><p>The authors declare no competing interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Data availability</head><p>Cif files for structures generated with USPEX can be found and downloaded at: https://github.com/ ElenaTrukhan/RL_structure_relaxation/tree/main/structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Code availability</head><p>The code that was used in the findings of this study is available from https://github.com/ElenaTrukhan/ RL_structure_relaxation.git. • Author contribution E.T. implemented the code, trained the reinforcement learning (RL) models, analyzed the experimental results, and wrote the manuscript; E.M. contributed to the code implementation; A.O. and E.M. supervised the work; all authors discussed the results and reviewed the manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix D Sensitivity</head><p>To investigate the sensitivity of our model near the minimum, we measured how the predictions differ between the structure corresponding to the minimum, s 0 , and the slightly distorted structure, s * . We introduced distortions by shifting the first atom from the minimum in X − Y plane: ⃗ r 1 (s * ) = ⃗ r 1 (s 0 ) + {∆x, ∆y, 0}. For this experiment, we selected a structure with 10 atoms (#15 in the Table <ref type="table">5</ref>). As mentioned in Section 3.4.2, we were able to train our model to relax this structure only up to forces of 0.2 eV/A, while further relaxation was challenging. Therefore, for predicting shifts ∆⃗ r 1 , we used the model trained to relax up to 0.2 eV/A and considered the range of ∆x and ∆y, where</p><p>2 eV/A (see Fig. <ref type="figure">8a</ref>). In Fig. <ref type="figure">8b</ref>) one can observe the logarithm of the norm of the difference in the model's predictions for the first atom, lg(|∆⃗ r 1 (s * ) − ∆⃗ r 1 (s 0 )|), as a function of ∆x and ∆y. In the close vicinity of the minimum, all input data in the crystal graphs change smoothly. However, in Fig. <ref type="figure">8b</ref>), a pronounced discontinuity in the model's predictions can be observed. This indicates that the model struggles to accurately predict atomic shifts further from the minimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix E Exploration in RL</head><p>Section 3.1 demonstrated that reducing the action space in accordance with the task's symmetry enables the Agent to identify an optimal policy more quickly. We also observed a similar effect in relation to exploration strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix F Additional greedy exploration</head><p>The performance of the TD3 Agent, with and without additional greedy exploration, was evaluated using different reward functions in two cases: (1) the hypothetical I4/mmm structure of Al and (2) a dataset of monoatomic Al and Fe structures (see Fig. <ref type="figure">11</ref>). Fig. <ref type="figure">10</ref> illustrates how the relaxation trajectory varies for the same initial configuration of the hypothetical I4/mmm structure of Al when using different trained models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix G Soft Actor Critic</head><p>In Soft-Actor Critic (SAC) <ref type="bibr" target="#b18">[20]</ref> <ref type="bibr" target="#b28">[30]</ref> the policy is stochastic so the entropy regularization term is introduced to the objective to provide with an exhaustive exploration of the Environment:</p><p>where α is the trade-off coefficient. It determines the relative importance of the entropy term H(π) = E a∼π [− log π(a|s)] against the reward and thus controls the stochasticity of the optimal policy.</p><p>As well as TD3, SAC utilizes two types of neural networks for Actor and Critic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.1 Loss functions</head><p>Soft Actor-Critic (SAC) is an off-policy algorithm that optimizes a stochastic policy, effectively bridging the gap between stochastic policy optimization and DDPG-style methods. Entropy regularization leads to a modification of the objective function</p><p>) . Q π and V π are also adjusted correspondingly <ref type="bibr" target="#b18">[20]</ref>.</p><p>SAC, similar to TD3, employs the concept of deriving an optimal policy from an optimal Q-function. There are also two models Q ϕ1 and Q ϕ2 , used for unbiased approximation of Q * , an optimal policy model π θ , and target models for the Q-functions. The loss function for Q ϕi is akin to the MSBE in Eq. ( <ref type="formula">11</ref>), but with additional entropy contribution:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix H Discount factor and level of exploration</head><p>The discount factor γ is a crucial parameter that influences how much the Agent values future rewards compared to immediate rewards. A higher γ assigns greater significance to long-term rewards, prompting the Agent to carefully consider future consequences in its decision-making process. However, depending on the task, the relationship between episodes may weaken as the number of time steps between them increases. This weak correlation, combined with the inclusion of long-term rewards, can introduce additional uncertainty into the estimation of value functions. In this case a lower γ is more suitable. Small discount factor also motivates the Agent to take more risks. Thus, both small and large γ have positive and negative effects, so in this work, we examined the performance of the model with different γ and levels of exploration. In the case of TD3 exploration is controlled by the parameter λ.</p><p>The lowest number of relaxation steps obtained in this work is presented in Fig. <ref type="figure">12a</ref>). More detailed comparison of learning curves is also shown in Fig. <ref type="figure">13</ref>.</p><p>As it can be seen, for TD3 in scenarios with high noise levels, increasing the discount factor leads to more stable convergence and improved performance in terms of score, last step, and maximum force. Conversely, in low-noise situations, a lower discount factor is preferable. This discrepancy arises from the impact of noise on value estimates. While high noise enhances exploration efficiency, it also introduces variance in value estimates. Consequently, a higher discount factor stabilizes policies by prioritizing long-term rewards over noisy immediate feedback. However, in low-noise scenarios, rewards are mainly generated by the policy itself, and a lower discount factor allows the Agent to focus more on the immediate results obtained by its policy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix I Additional figures and Tables</head><p>I.1 Hyperparameters tuning: discount factor and level of exploration Fig. <ref type="figure">13</ref>, Fig. <ref type="figure">14</ref>, Fig. <ref type="figure">15</ref> and Table <ref type="table">3</ref>, Table <ref type="table">4</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix J Structures and potentials</head><p>The model was trained on Al and Fe binary configurations and monoatomic Al and Fe configurations. For the calculation of forces, energies, and stress tensors was chosen Embedded-Atom Method (EAM). For calculations with N ≤ 4 we used structured form Materials Project while for higher N we generated structures using USPEX code <ref type="bibr" target="#b36">[38]</ref> and randomly chose one configuration for each N . All structures along with their Materials Project ID <ref type="bibr" target="#b39">[41]</ref> (if such exist) and links to potentials are listed in Table <ref type="table">5</ref>. For all TFN models mul = 20, number of neighbors = 25, emdim = 10, number of basis=10, radial layers=1, radial neurons=100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix K Hyperparameters</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Georg</forename><surname>Kresse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martijn</forename><surname>Marsman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Poeltl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Merzuk</forename><surname>Kaltak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ferenc</forename><surname>Karsai</surname></persName>
		</author>
		<ptr target="https://www.vasp.at/wiki/index.php/Category:Ionic_minimization" />
		<title level="m">Ionic Minimization in VASP</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Convergence acceleration of iterative sequences. The case of SCF iteration</title>
		<author>
			<persName><forename type="first">Péter</forename><surname>Pulay</surname></persName>
		</author>
		<idno type="DOI">10.1016/0009-2614(80)80396-4</idno>
	</analytic>
	<monogr>
		<title level="j">Chemical Physics Letters</title>
		<idno type="ISSN">0009-2614</idno>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="393" to="398" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">H</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Flannery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Teukolsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Vetterling</surname></persName>
		</author>
		<title level="m">Numerical Recipes: The Art of Scientific Computing</title>
				<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
	<note>1st edition</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An efficient Monte Carlo algorithm for determining the minimum energy structures of metallic grain boundaries</title>
		<author>
			<persName><forename type="first">Arash</forename><surname>Dehghan Banadaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Tschopp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srikanth</forename><surname>Patala</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.commatsci.2018.09.017</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Materials Science</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="page" from="466" to="475" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Conformation-family Monte Carlo: A new method for crystal structure prediction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pillardy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Arnautova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Czaplewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Scheraga</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.231479298</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="12351" to="12356" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Crystal structure and pair potentials: A molecular-dynamics study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Parrinello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rahman</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.45.1196</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1196" to="1199" />
			<date type="published" when="1980">1980</date>
			<publisher>American Physical Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Accelerating crystal structure prediction by machine-learning interatomic potentials with active learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Evgeny</surname></persName>
		</author>
		<author>
			<persName><surname>Podryabinkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Evgeny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">V</forename><surname>Tikhonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><forename type="middle">R</forename><surname>Shapeev</surname></persName>
		</author>
		<author>
			<persName><surname>Oganov</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevB.99.064114</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. B</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">64114</biblScope>
			<date type="published" when="2019-02">February 2019</date>
			<publisher>American Physical Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A low resources space time approach to the GW approximation</title>
		<author>
			<persName><forename type="first">Dietrich</forename><surname>Foerster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saber</forename><surname>Gueddida</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.commatsci.2020.110078</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Materials Science</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="page">110078</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A quantitative study of the scaling properties of the Hartree-Fock method</title>
		<author>
			<persName><forename type="first">Douglas</forename><forename type="middle">L</forename><surname>Strout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><forename type="middle">E</forename><surname>Scuseria</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.468836</idno>
	</analytic>
	<monogr>
		<title level="j">The Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="8448" to="8452" />
			<date type="published" when="1995-06">June 1995</date>
			<publisher>AIP Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Parametrically constrained geometry relaxations for high-throughput materials science</title>
		<author>
			<persName><forename type="first">Maja-Olivia</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">A R</forename><surname>Purcell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Curtarolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Scheffler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Carbogno</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41524-019-0254-4</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Materials</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">123</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Deep reinforcement learning for inverse inorganic materials design. npj Computational Materials</title>
		<author>
			<persName><forename type="first">Elton</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Karpovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elsa</forename><surname>Olivetti</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41524-024-01474-5</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">287</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for digital materials design</title>
		<author>
			<persName><forename type="first">Fanping</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiqi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhizhou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grace</forename><forename type="middle">X</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1021/acsmaterialslett.1c00390</idno>
	</analytic>
	<monogr>
		<title level="j">ACS Materials Letters</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1433" to="1439" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning in continuous action space for developing high dimensional potential energy models</title>
		<author>
			<persName><forename type="first">Sukriti</forename><surname>Manna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Troy</forename><surname>Loeffler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohit</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suvo</forename><surname>Banik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henry</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bilvin</forename><surname>Varughese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kiran</forename><surname>Sasikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Sternberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Peterka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathew</forename><surname>Cherukara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bobby</forename><surname>Sumpter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subramanian</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-021-27849-6</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Optimization of molecules via deep reinforcement learning</title>
		<author>
			<persName><forename type="first">Zhenpeng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">N</forename><surname>Zare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Riley</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-019-47148-x</idno>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">10752</biblScope>
			<date type="published" when="2019-07">July 2019</date>
			<publisher>Springer Science and Business Media LLC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Towards efficient discovery of green synthetic pathways with Monte Carlo tree search and reinforcement learning</title>
		<author>
			<persName><forename type="first">Xiaoxue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Connor</forename><forename type="middle">W</forename><surname>Coley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klavs</forename><forename type="middle">F</forename><surname>Jensen</surname></persName>
		</author>
		<idno type="DOI">10.1039/d0sc04184j</idno>
	</analytic>
	<monogr>
		<title level="j">Chemical Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">40</biblScope>
			<biblScope unit="page" from="10959" to="10972" />
			<date type="published" when="2020">2020</date>
			<publisher>Royal Society of Chemistry</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Discovering mechanisms for materials microstructure optimization via reinforcement learning of a generative model</title>
		<author>
			<persName><forename type="first">K</forename><surname>Rama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erick</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergei</forename><forename type="middle">V</forename><surname>Orozco</surname></persName>
		</author>
		<author>
			<persName><surname>Kalinin</surname></persName>
		</author>
		<idno type="DOI">10.1088/2632-2153/aca004</idno>
	</analytic>
	<monogr>
		<title level="j">Machine Learning: Science and Technology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="04L" to="T7" />
			<date type="published" when="2022">2022</date>
			<publisher>IOP Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties</title>
		<author>
			<persName><forename type="first">Tian</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">C</forename><surname>Grossman</surname></persName>
		</author>
		<idno type="DOI">10.1103/physrevlett.120.145301</idno>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">14</biblScope>
			<date type="published" when="2018">2018</date>
			<publisher>American Physical Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Addressing function approximation error in actor-critic methods</title>
		<author>
			<persName><forename type="first">Scott</forename><surname>Fujimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herke</forename><surname>Van Hoof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Meger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.09477</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor</title>
		<author>
			<persName><forename type="first">Tuomas</forename><surname>Haarnoja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurick</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.01290</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Computer simulation of point defect properties in dilute Fe-Cu alloy using a many-body interatomic potential</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Ackland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Bacon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Harry</surname></persName>
		</author>
		<idno type="DOI">10.1080/01418619708207198</idno>
	</analytic>
	<monogr>
		<title level="j">Philosophical Magazine A</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="713" to="732" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Interatomic potentials for atomistic simulations of the Ti-Al system</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rajendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zope</surname></persName>
		</author>
		<author>
			<persName><surname>Mishin</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevB.68.024102</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. B</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">24102</biblScope>
			<date type="published" when="2003-07">July 2003</date>
			<publisher>American Physical Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Effect of Fe segregation on the migration of a non-symmetric Σ5 tilt grain boundary in Al</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Mendelev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Srolovitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Ackland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sangcheol</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1557/JMR.2005.0024</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Materials Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="208" to="218" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The convergence of a class of double-rank minimization algorithms 1. General considerations</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Broyden</surname></persName>
		</author>
		<idno type="DOI">10.1093/imamat/6.1.76</idno>
	</analytic>
	<monogr>
		<title level="j">IMA Journal of Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="76" to="90" />
			<date type="published" when="1970-03">March 1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A new approach to variable metric algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
		<idno type="DOI">10.1093/comjnl/13.3.317</idno>
	</analytic>
	<monogr>
		<title level="j">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="317" to="322" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A family of variable-metric methods derived by variational means</title>
		<author>
			<persName><forename type="first">D</forename><surname>Goldfarb</surname></persName>
		</author>
		<idno type="DOI">10.2307/2004873</idno>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">109</biblScope>
			<biblScope unit="page" from="23" to="23" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Conditioning of quasi-Newton methods for function minimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Shanno</surname></persName>
		</author>
		<idno type="DOI">10.1090/S0025-5718-1970-0274029-X</idno>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">111</biblScope>
			<biblScope unit="page" from="647" to="656" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Methods of conjugate gradients for solving linear systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Hestenes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Stiefel</surname></persName>
		</author>
		<idno type="DOI">10.6028/JRES.049.044</idno>
	</analytic>
	<monogr>
		<title level="j">J. Res. Natl. Bur. Stand</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">409</biblScope>
			<date type="published" when="1934-12">1934. December 1952</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Reinforcement Learning: An Introduction</title>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Achiam</surname></persName>
		</author>
		<ptr target="https://spinningup.openai.com/en/latest/" />
		<title level="m">Spinning Up in Deep Reinforcement Learning</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Reinforcement Learning: Industrial Applications of Intelligent Agents</title>
		<author>
			<persName><forename type="first">Phil</forename><surname>Winder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<pubPlace>O&apos;Reilly Media, Inc., Sebastopol, CA</pubPlace>
		</imprint>
	</monogr>
	<note>1st edition</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials</title>
		<author>
			<persName><forename type="first">Simon</forename><surname>Batzner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Musaelian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lixin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">P</forename><surname>Mailoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mordechai</forename><surname>Kornbluth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Molinari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tess</forename><forename type="middle">E</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Kozinsky</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-022-29939-5</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2022">2022</date>
			<publisher>Springer Science and Business Media LLC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Mario</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tess</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wouter</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradley</forename><surname>Boomsma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kostiantyn</forename><surname>Dice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maurice</forename><surname>Lapchevskyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michał</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Tyszkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Batzner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Madisetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jes</forename><surname>Uhrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nuri</forename><surname>Frellsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophia</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingjian</forename><surname>Sanborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Rackers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Rød</surname></persName>
		</author>
		<author>
			<persName><surname>Bailey</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.6459381</idno>
		<title level="m">Euclidean neural networks: e3nn. Zenodo</title>
				<imprint>
			<date type="published" when="2022-04">April 2022</date>
		</imprint>
	</monogr>
	<note>Version 0.5.0</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludwig</forename><surname>Pettersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><forename type="middle">Openai</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><surname>Gym</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01540</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A robust, open-source Python library for materials analysis</title>
		<author>
			<persName><forename type="first">Ping</forename><surname>Shyue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">Davidson</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anubhav</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffroy</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Hautier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shreyas</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Cholia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><forename type="middle">L</forename><surname>Gunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristin</forename><forename type="middle">A</forename><surname>Chevrier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerbrand</forename><surname>Persson</surname></persName>
		</author>
		<author>
			<persName><surname>Ceder</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.commatsci.2012.10.028</idno>
		<ptr target="https://doi.org/10.1016/j.commatsci.2012.10.028" />
	</analytic>
	<monogr>
		<title level="j">Computational Materials Science</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="314" to="319" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Python Materials Genomics</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The atomic simulation environment-a Python library for working with atoms</title>
		<author>
			<persName><forename type="first">Ask</forename><surname>Hjorth Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><forename type="middle">Jørgen</forename><surname>Mortensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Blomqvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivano</forename><forename type="middle">E</forename><surname>Castelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rune</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Dułak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesper</forename><surname>Friis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">N</forename><surname>Groves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bjørk</forename><surname>Hammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cory</forename><surname>Hargus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">D</forename><surname>Hermes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">C</forename><surname>Jennings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">Bjerre</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Kermode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">R</forename><surname>Kitchin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonhard</forename><surname>Esben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Kolsbjerg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristen</forename><surname>Kubal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steen</forename><surname>Kaasbjerg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jón</forename><surname>Lysgaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Bergmann Maronsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Maxson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Olsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Pastewka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carsten</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Rostgaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ole</forename><surname>Schiøtz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikkel</forename><surname>Schütt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><forename type="middle">S</forename><surname>Strange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tejs</forename><surname>Thygesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lasse</forename><surname>Vegge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Vilhelmsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhua</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karsten</forename><forename type="middle">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><surname>Jacobsen</surname></persName>
		</author>
		<idno type="DOI">10.1088/1361-648X/aa680e</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Physics: Condensed Matter</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">27</biblScope>
			<biblScope unit="page">273002</biblScope>
			<date type="published" when="2017">2017</date>
			<publisher>IOP Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Finding symmetry breaking order parameters with Euclidean neural networks</title>
		<author>
			<persName><forename type="first">Tess</forename><forename type="middle">E</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><forename type="middle">Kurt</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1103/physrevresearch.3.l012002</idno>
	</analytic>
	<monogr>
		<title level="j">Physical Review Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021-01">January 2021</date>
			<publisher>American Physical Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">USPEX-Evolutionary crystal structure prediction</title>
		<author>
			<persName><forename type="first">Colin</forename><forename type="middle">W</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><forename type="middle">R</forename><surname>Oganov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaus</forename><surname>Hansen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cpc.2006.07.020</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Physics Communications</title>
		<imprint>
			<biblScope unit="volume">175</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="713" to="720" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">J</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Tassa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.02971</idno>
		<title level="m">Continuous control with deep reinforcement learning</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Understanding failures of deterministic actor-critic with continuous action spaces and sparse rewards</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Matheron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Perrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Sigaud</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-61616-8_25</idno>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks and Machine Learning -ICANN 2020: 29th International Conference on Artificial Neural Networks</title>
				<meeting><address><addrLine>Bratislava, Slovakia; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2020">September 15-18, 2020. 2020</date>
			<biblScope unit="page" from="308" to="320" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Commentary: The Materials Project: A materials genome approach to accelerating materials innovation</title>
		<author>
			<persName><forename type="first">Anubhav</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Shyue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffroy</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hautier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">Davidson</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shreyas</forename><surname>Dacek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Cholia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Gunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerbrand</forename><surname>Skinner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristin</forename><forename type="middle">A</forename><surname>Ceder</surname></persName>
		</author>
		<author>
			<persName><surname>Persson</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.4812323</idno>
	</analytic>
	<monogr>
		<title level="j">APL Materials</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">11002</biblScope>
			<date type="published" when="2013-07">July 2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
